{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow import distribute\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the list of GPUs available\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# Enable memory growth on each GPU\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "if gpus:\n",
    "    try:\n",
    "        # Set memory limit for the first GPU\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])  # Limit to 1GB, for example\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 \n",
    "learning_rate = 0.005\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(training_images, training_labels) , (validation_images, validation_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "def preprocess_image_input(input_images):\n",
    "  input_images = input_images.astype('float32')\n",
    "  output_ims = preprocess_input(input_images)\n",
    "  return output_ims\n",
    "strategy = distribute.get_strategy()\n",
    "with strategy.scope():\n",
    "    fe_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(fpath, label_key=\"labels\"):\n",
    "    \"\"\"Internal utility for parsing CIFAR data.\n",
    "\n",
    "    Args:\n",
    "        fpath: path the file to parse.\n",
    "        label_key: key for label data in the retrieve\n",
    "            dictionary.\n",
    "\n",
    "    Returns:\n",
    "        A tuple `(data, labels)`.\n",
    "    \"\"\"\n",
    "    with open(fpath, \"rb\") as f:\n",
    "        d = pickle.load(f, encoding=\"bytes\")\n",
    "        # decode utf8\n",
    "        d_decoded = {}\n",
    "        for k, v in d.items():\n",
    "            d_decoded[k.decode(\"utf8\")] = v\n",
    "        d = d_decoded\n",
    "    data = d[\"data\"]\n",
    "    labels = d[label_key]\n",
    "\n",
    "    data = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    return data, labels\n",
    "\n",
    "def load_data_keras(path):\n",
    "    num_train_samples = 50000\n",
    "    \n",
    "    x_train = np.empty((10000, 3, 32, 32), dtype=\"uint8\")\n",
    "    y_train = np.empty((num_train_samples,), dtype=\"uint8\")\n",
    "    features_train = []\n",
    "    # batches are within an inner folder\n",
    "    path = os.path.join(path, \"cifar-10-batches-py\")\n",
    "    for i in range(1, 6):\n",
    "        fpath = os.path.join(path, \"data_batch_\" + str(i))\n",
    "        print(fpath)\n",
    "        (\n",
    "            x_train,\n",
    "            y_train[(i - 1) * 10000 : i * 10000],\n",
    "        ) = load_batch(fpath)\n",
    "        X_train = preprocess_image_input(x_train.transpose(0, 2, 3, 1))\n",
    "        print(X_train.shape)\n",
    "        features_train.append(fe_model.predict(X_train, verbose=1))\n",
    "        \n",
    "    fpath = os.path.join(path, \"test_batch\")\n",
    "    x_test, y_test = load_batch(fpath)\n",
    "    X_test = preprocess_image_input(x_test.transpose(0, 2, 3, 1))\n",
    "    features_test = fe_model.predict(X_test, verbose=1)\n",
    "    \n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "    y_test = np.reshape(y_test, (len(y_test), 1))\n",
    "    \n",
    "    return (features_train, y_train), (features_test, y_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/cifar-10-batches-py/data_batch_1\n",
      "(10000, 32, 32, 3)\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step\n",
      "../Data/cifar-10-batches-py/data_batch_2\n",
      "(10000, 32, 32, 3)\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step\n",
      "../Data/cifar-10-batches-py/data_batch_3\n",
      "(10000, 32, 32, 3)\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step\n",
      "../Data/cifar-10-batches-py/data_batch_4\n",
      "(10000, 32, 32, 3)\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step\n",
      "../Data/cifar-10-batches-py/data_batch_5\n",
      "(10000, 32, 32, 3)\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 30ms/step\n"
     ]
    }
   ],
   "source": [
    "(features_train, training_labels) , (features_test, validation_labels) = load_data_keras(\"../Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = np.concatenate(features_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,490</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m20,490\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,490</span> (80.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,490\u001b[0m (80.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,490</span> (80.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,490\u001b[0m (80.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_features = features_train.shape[1:]\n",
    "log_model = Sequential([\n",
    "    Input(shape=n_features),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "log_model.compile(optimizer=Adam(learning_rate=learning_rate), loss=SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
    "log_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1540/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.5152 - loss: 4.0450\n",
      "Epoch 1: val_accuracy improved from -inf to 0.60290, saving model to model/resnet_model.keras\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526us/step - accuracy: 0.5157 - loss: 4.0464 - val_accuracy: 0.6029 - val_loss: 4.0534\n",
      "Epoch 2/10\n",
      "\u001b[1m1517/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.6135 - loss: 3.7065\n",
      "Epoch 2: val_accuracy did not improve from 0.60290\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 416us/step - accuracy: 0.6132 - loss: 3.7157 - val_accuracy: 0.5678 - val_loss: 5.2304\n",
      "Epoch 3/10\n",
      "\u001b[1m1453/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.6300 - loss: 3.6830\n",
      "Epoch 3: val_accuracy did not improve from 0.60290\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 393us/step - accuracy: 0.6293 - loss: 3.7036 - val_accuracy: 0.6005 - val_loss: 4.7034\n",
      "Epoch 4/10\n",
      "\u001b[1m1532/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.6347 - loss: 3.8678\n",
      "Epoch 4: val_accuracy improved from 0.60290 to 0.61390, saving model to model/resnet_model.keras\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 444us/step - accuracy: 0.6346 - loss: 3.8727 - val_accuracy: 0.6139 - val_loss: 4.7585\n",
      "Epoch 5/10\n",
      "\u001b[1m1510/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.6455 - loss: 3.7127\n",
      "Epoch 5: val_accuracy did not improve from 0.61390\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 381us/step - accuracy: 0.6452 - loss: 3.7237 - val_accuracy: 0.5841 - val_loss: 5.2921\n",
      "Epoch 6/10\n",
      "\u001b[1m1521/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 330us/step - accuracy: 0.6489 - loss: 3.8829\n",
      "Epoch 6: val_accuracy did not improve from 0.61390\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 377us/step - accuracy: 0.6487 - loss: 3.8893 - val_accuracy: 0.5923 - val_loss: 5.7335\n",
      "Epoch 7/10\n",
      "\u001b[1m1455/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.6490 - loss: 3.9251\n",
      "Epoch 7: val_accuracy did not improve from 0.61390\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413us/step - accuracy: 0.6487 - loss: 3.9403 - val_accuracy: 0.5902 - val_loss: 5.6060\n",
      "Epoch 8/10\n",
      "\u001b[1m1461/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.6574 - loss: 3.8589\n",
      "Epoch 8: val_accuracy did not improve from 0.61390\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426us/step - accuracy: 0.6567 - loss: 3.8787 - val_accuracy: 0.6053 - val_loss: 5.3567\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 335us/step - accuracy: 0.6566 - loss: 3.9189\n",
      "Epoch 9: val_accuracy did not improve from 0.61390\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 383us/step - accuracy: 0.6563 - loss: 3.9280 - val_accuracy: 0.6002 - val_loss: 5.5559\n",
      "Epoch 10/10\n",
      "\u001b[1m1514/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 332us/step - accuracy: 0.6651 - loss: 3.7894\n",
      "Epoch 10: val_accuracy did not improve from 0.61390\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 378us/step - accuracy: 0.6646 - loss: 3.8002 - val_accuracy: 0.5955 - val_loss: 5.7135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x325ab2570>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'model/resnet_model.keras',             # Path where to save the model\n",
    "    monitor='val_accuracy',       # Metric to monitor\n",
    "    save_best_only=True,          # Save only the best model\n",
    "    mode='max',                   # Mode for choosing the best value ('max' since higher accuracy is better)\n",
    "    verbose=1                     # Verbose output to see when checkpoints are saved\n",
    ")\n",
    "log_model.fit(features_train, training_labels, batch_size=BATCH_SIZE, epochs=10, validation_data=(features_test, validation_labels), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane     0.6467    0.6680    0.6572      1000\n",
      "  automobile     0.6109    0.7050    0.6546      1000\n",
      "        bird     0.5652    0.4640    0.5096      1000\n",
      "         cat     0.4112    0.6040    0.4893      1000\n",
      "        deer     0.5579    0.5060    0.5307      1000\n",
      "         dog     0.5286    0.5090    0.5186      1000\n",
      "        frog     0.6402    0.6280    0.6340      1000\n",
      "       horse     0.7462    0.4910    0.5923      1000\n",
      "        ship     0.7479    0.6970    0.7215      1000\n",
      "       truck     0.6312    0.6830    0.6561      1000\n",
      "\n",
      "    accuracy                         0.5955     10000\n",
      "   macro avg     0.6086    0.5955    0.5964     10000\n",
      "weighted avg     0.6086    0.5955    0.5964     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "probabilities = log_model.predict(features_test, batch_size=128)\n",
    "\n",
    "probabilities = np.argmax(probabilities, axis = 1)\n",
    "\n",
    "print(classification_report(validation_labels, probabilities, target_names= ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'], digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
