{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab.\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow import distribute\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the list of GPUs available\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# Enable memory growth on each GPU\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "if gpus:\n",
    "    try:\n",
    "        # Set memory limit for the first GPU\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])  # Limit to 1GB, for example\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 \n",
    "learning_rate = 0.005\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "image_size = (32, 32, 3)\n",
    "sampling = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(training_images, training_labels) , (validation_images, validation_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "def preprocess_image_input(input_images):\n",
    "  input_images = input_images.astype('float32')\n",
    "  input_images = tf.keras.layers.UpSampling2D(size=(sampling, sampling))(input_images)\n",
    "  output_ims = preprocess_input(input_images)\n",
    "  return output_ims\n",
    "strategy = distribute.get_strategy()\n",
    "with strategy.scope():\n",
    "    fe_model = ResNet50(weights='imagenet', include_top=False, input_shape=(image_size[0] * sampling, image_size[1] * sampling, image_size[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(fpath, label_key=\"labels\"):\n",
    "    \"\"\"Internal utility for parsing CIFAR data.\n",
    "\n",
    "    Args:\n",
    "        fpath: path the file to parse.\n",
    "        label_key: key for label data in the retrieve\n",
    "            dictionary.\n",
    "\n",
    "    Returns:\n",
    "        A tuple `(data, labels)`.\n",
    "    \"\"\"\n",
    "    with open(fpath, \"rb\") as f:\n",
    "        d = pickle.load(f, encoding=\"bytes\")\n",
    "        # decode utf8\n",
    "        d_decoded = {}\n",
    "        for k, v in d.items():\n",
    "            d_decoded[k.decode(\"utf8\")] = v\n",
    "        d = d_decoded\n",
    "    data = d[\"data\"]\n",
    "    labels = d[label_key]\n",
    "\n",
    "    data = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    return data, labels\n",
    "\n",
    "def load_data_keras(path):\n",
    "    num_train_samples = 50000\n",
    "    \n",
    "    x_train = np.empty((10000, 3, 32, 32), dtype=\"uint8\")\n",
    "    y_train = np.empty((num_train_samples,), dtype=\"uint8\")\n",
    "    features_train = []\n",
    "    # batches are within an inner folder\n",
    "    path = os.path.join(path, \"cifar-10-batches-py\")\n",
    "    for i in range(1, 6):\n",
    "        fpath = os.path.join(path, \"data_batch_\" + str(i))\n",
    "        print(fpath)\n",
    "        (\n",
    "            x_train,\n",
    "            y_train[(i - 1) * 10000 : i * 10000],\n",
    "        ) = load_batch(fpath)\n",
    "        X_train = preprocess_image_input(x_train.transpose(0, 2, 3, 1))\n",
    "        print(X_train.shape)\n",
    "        features_train.append(fe_model.predict(X_train, verbose=1))\n",
    "        \n",
    "    fpath = os.path.join(path, \"test_batch\")\n",
    "    x_test, y_test = load_batch(fpath)\n",
    "    X_test = preprocess_image_input(x_test.transpose(0, 2, 3, 1))\n",
    "    features_test = fe_model.predict(X_test, verbose=1)\n",
    "    \n",
    "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
    "    y_test = np.reshape(y_test, (len(y_test), 1))\n",
    "    \n",
    "    return (features_train, y_train), (features_test, y_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/cifar-10-batches-py/data_batch_1\n",
      "(10000, 64, 64, 3)\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 68ms/step\n",
      "../Data/cifar-10-batches-py/data_batch_2\n",
      "(10000, 64, 64, 3)\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 69ms/step\n",
      "../Data/cifar-10-batches-py/data_batch_3\n",
      "(10000, 64, 64, 3)\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 71ms/step\n",
      "../Data/cifar-10-batches-py/data_batch_4\n",
      "(10000, 64, 64, 3)\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 69ms/step\n",
      "../Data/cifar-10-batches-py/data_batch_5\n",
      "(10000, 64, 64, 3)\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 70ms/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 69ms/step\n"
     ]
    }
   ],
   "source": [
    "(features_train, training_labels) , (features_test, validation_labels) = load_data_keras(\"../Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = np.concatenate(features_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">81,930</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m81,930\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,930</span> (320.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m81,930\u001b[0m (320.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">81,930</span> (320.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m81,930\u001b[0m (320.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_features = features_train.shape[1:]\n",
    "log_model = Sequential([\n",
    "    Input(shape=n_features),\n",
    "    Flatten(),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "log_model.compile(optimizer=Adam(learning_rate=learning_rate), loss=SparseCategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
    "log_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1537/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.6835 - loss: 9.2665\n",
      "Epoch 1: val_accuracy improved from -inf to 0.76200, saving model to model/resnet_model.keras\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735us/step - accuracy: 0.6841 - loss: 9.2780 - val_accuracy: 0.7620 - val_loss: 9.4282\n",
      "Epoch 2/10\n",
      "\u001b[1m1540/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 556us/step - accuracy: 0.7986 - loss: 7.2866\n",
      "Epoch 2: val_accuracy improved from 0.76200 to 0.77060, saving model to model/resnet_model.keras\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - accuracy: 0.7986 - loss: 7.2979 - val_accuracy: 0.7706 - val_loss: 11.3913\n",
      "Epoch 3/10\n",
      "\u001b[1m1523/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.8272 - loss: 6.4531\n",
      "Epoch 3: val_accuracy did not improve from 0.77060\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 582us/step - accuracy: 0.8271 - loss: 6.4678 - val_accuracy: 0.7555 - val_loss: 13.2183\n",
      "Epoch 4/10\n",
      "\u001b[1m1481/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.8448 - loss: 5.9770\n",
      "Epoch 4: val_accuracy improved from 0.77060 to 0.77600, saving model to model/resnet_model.keras\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601us/step - accuracy: 0.8444 - loss: 6.0054 - val_accuracy: 0.7760 - val_loss: 12.5620\n",
      "Epoch 5/10\n",
      "\u001b[1m1552/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 0.8628 - loss: 5.2136\n",
      "Epoch 5: val_accuracy did not improve from 0.77600\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step - accuracy: 0.8628 - loss: 5.2170 - val_accuracy: 0.7718 - val_loss: 13.9889\n",
      "Epoch 6/10\n",
      "\u001b[1m1551/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 551us/step - accuracy: 0.8746 - loss: 4.7848\n",
      "Epoch 6: val_accuracy did not improve from 0.77600\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - accuracy: 0.8745 - loss: 4.7889 - val_accuracy: 0.7688 - val_loss: 15.1966\n",
      "Epoch 7/10\n",
      "\u001b[1m1520/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.8869 - loss: 4.1707\n",
      "Epoch 7: val_accuracy improved from 0.77600 to 0.78170, saving model to model/resnet_model.keras\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.8867 - loss: 4.1890 - val_accuracy: 0.7817 - val_loss: 15.2760\n",
      "Epoch 8/10\n",
      "\u001b[1m1548/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.8968 - loss: 3.7846\n",
      "Epoch 8: val_accuracy did not improve from 0.78170\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - accuracy: 0.8967 - loss: 3.7909 - val_accuracy: 0.7796 - val_loss: 15.8192\n",
      "Epoch 9/10\n",
      "\u001b[1m1540/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 555us/step - accuracy: 0.9033 - loss: 3.6813\n",
      "Epoch 9: val_accuracy did not improve from 0.78170\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616us/step - accuracy: 0.9032 - loss: 3.6875 - val_accuracy: 0.7775 - val_loss: 17.6924\n",
      "Epoch 10/10\n",
      "\u001b[1m1516/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.9085 - loss: 3.3998\n",
      "Epoch 10: val_accuracy did not improve from 0.78170\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - accuracy: 0.9083 - loss: 3.4141 - val_accuracy: 0.7792 - val_loss: 17.8893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x453485940>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'model/resnet_model.keras',             # Path where to save the model\n",
    "    monitor='val_accuracy',       # Metric to monitor\n",
    "    save_best_only=True,          # Save only the best model\n",
    "    mode='max',                   # Mode for choosing the best value ('max' since higher accuracy is better)\n",
    "    verbose=1                     # Verbose output to see when checkpoints are saved\n",
    ")\n",
    "log_model.fit(features_train, training_labels, batch_size=BATCH_SIZE, epochs=10, validation_data=(features_test, validation_labels), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 582us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane     0.7610    0.8470    0.8017      1000\n",
      "  automobile     0.8526    0.8910    0.8714      1000\n",
      "        bird     0.7417    0.7380    0.7398      1000\n",
      "         cat     0.6647    0.5750    0.6166      1000\n",
      "        deer     0.7546    0.6580    0.7030      1000\n",
      "         dog     0.7453    0.7110    0.7277      1000\n",
      "        frog     0.7581    0.8870    0.8175      1000\n",
      "       horse     0.7323    0.8700    0.7952      1000\n",
      "        ship     0.8734    0.8420    0.8574      1000\n",
      "       truck     0.9269    0.7730    0.8430      1000\n",
      "\n",
      "    accuracy                         0.7792     10000\n",
      "   macro avg     0.7811    0.7792    0.7773     10000\n",
      "weighted avg     0.7811    0.7792    0.7773     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "probabilities = log_model.predict(features_test, batch_size=128)\n",
    "\n",
    "probabilities = np.argmax(probabilities, axis = 1)\n",
    "\n",
    "print(classification_report(validation_labels, probabilities, target_names= ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'], digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
